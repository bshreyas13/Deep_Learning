{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM_ImageCap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQMIygl30n2F"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "from os import listdir\n",
        "from pickle import dump, load\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from time import time\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import progressbar\n",
        "from time import sleep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TABgTQ7sEvdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9263ef02-d6b3-4293-97ce-205143704e5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tOGrh0wE5ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510909db-c28b-42ff-e1a8-a44cf355779a"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "customized_path = 'DeepLearning'\n",
        "sys_path = os.path.join(prefix, customized_path)\n",
        "sys.path.append(sys_path)\n",
        "%cd /content/gdrive/MyDrive/DeepLearning\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/DeepLearning\n",
            "best_model_c100.h5\t\tImageCap_Data\n",
            "best_model_c10.h5\t\tMidTerm\n",
            "best_resnet_model_c100.h5\tmodel_inceptionv3.png\n",
            "best_resnet_model_c10.h5\tmodel_inceptionv.png\n",
            "best_tf_resnet50_model_c100.h5\tmodel.png\n",
            "best_tf_resnet50_model_c10.h5\tMR_CNN_model.h5\n",
            "c10_resnet20_model.103.h5\tMultiresCNN-network.png\n",
            "cat.png\t\t\t\tPaaperPresentation.gslides\n",
            "cnn-y-network.png\t\tresnet.png\n",
            "descriptions_test.txt\t\tsample_data\n",
            "descriptions.txt\t\tsaved_models\n",
            "features_test_Inception.pkl\tsaved_models_mrc\n",
            "features_test.pkl\t\tsaved_models_mt\n",
            "features_train_Inception.pkl\tVC_CNN_model.h5\n",
            "features_train.pkl\t\tVGG_CNN_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_CS9pUXWF5U"
      },
      "source": [
        "# Funtion to Extract features from each photo in the directory\n",
        "def extract_features(directory, model_name):\n",
        "\n",
        "    CNN_models = [VGG16(weights=\"imagenet\"),InceptionV3(weights=\"imagenet\")]\n",
        "    \n",
        "    if model_name == \"VGG16\" :    \n",
        "      # Loading the model\n",
        "      model = CNN_models[0]\n",
        "      input_img_shape = (224,224)\n",
        "      # For VGG16 Removing the last layer from the loaded model as we require only the features not the classification \n",
        "      model.layers.pop()\n",
        "      model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "      print(model.summary())\n",
        "\n",
        "    elif model_name == \"InceptionV3\":\n",
        "      model = CNN_models[1]\n",
        "      input_img_shape = (299,299)\n",
        "      # Create a new model, by removing the last layer (output layer) from the inception v3\n",
        "      model = Model(model.input, model.layers[-2].output)\n",
        "      # Summarizing the model \n",
        "      print(model.summary())\n",
        "\n",
        "    else:\n",
        "      print(\"Select a model from VGG16 or InceptionV3\"+\"\\n\"+\"More models to be added\")\n",
        "    # Extracting features from each photo and storing it in a dictionary \n",
        "    features = dict()\n",
        "    bar = progressbar.ProgressBar(maxval=len(listdir(directory)), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        "    \n",
        "    for i,name in enumerate(listdir(directory)):\n",
        "\n",
        "        # Defining the path of the image \n",
        "        filename = directory + '/' + name\n",
        "        \n",
        "        # Loading an image and converting it into size 224 * 224\n",
        "        ## Yet to be automated. For now manually change to appropriate input size\n",
        "        image = load_img(filename, target_size=input_img_shape)\n",
        "        \n",
        "        # Converting the image pixels into a numpy array\n",
        "        image = img_to_array(image)\n",
        "       # Reshaping data for the model\n",
        "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "        \n",
        "        # Preprocessing the images for the VGG model\n",
        "        # The preprocess_input function is meant to adequate your image to the format the model requires.\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # Getting features of an image\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        \n",
        "        # Getting the image name\n",
        "        image_id = name.split('.')[0]\n",
        "\n",
        "        # Storing the feature corresponding to the image in the dictionary\n",
        "        features[image_id] = feature\n",
        "        bar.update(i+1)\n",
        "        sleep(0.1)\n",
        "        #print('>%s' % name)\n",
        "    bar.finish()\n",
        "        \n",
        "        \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNbmT4aNomV2"
      },
      "source": [
        "# Loading the file containg all the descriptions into memory\n",
        "\n",
        "def load_doc(filename):\n",
        "    # Opening the file as read only\n",
        "    file = open(filename, 'r')\n",
        "\n",
        "    # Reading all text and storing it.\n",
        "    text = file.read()\n",
        "\n",
        "    # Closing the file\n",
        "    file.close()\n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHk65XVHjdle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c41d0a-4a1d-4296-b2ee-6762f7029086"
      },
      "source": [
        "# Defining the directory we are using\n",
        "directory_train = 'ImageCap_Data/VizWiz_Data_train1/train1'\n",
        "\n",
        "\n",
        "## Extracting features from all the images\n",
        "# Here we also set(by name) the model used for generating image vectors\n",
        "model_names = [\"VGG16\",\"InceptionV3\"] \n",
        "\n",
        "start = time()\n",
        "features_train = extract_features(directory_train,model_names[0])\n",
        "dump(features_train, open('features_train.pkl', 'wb'))\n",
        "print(\"Time taken to encode train set in seconds =\", time()-start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8ynNqZuvGsz",
        "outputId": "b675aad0-ab5a-44be-c312-9c3611db1011"
      },
      "source": [
        "print('Extracted Features using VGG16: ', len(features_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted Features using VGG16:  8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIKV3O-3vFSD",
        "outputId": "66652dca-876c-426d-9b42-103118b09b77"
      },
      "source": [
        "directory_test = 'ImageCap_Data/VizWiz_Data_val/val/val'\n",
        "model_names = [\"VGG16\",\"InceptionV3\"] \n",
        "start = time()\n",
        "features_test = extract_features(directory_test,model_names[0])\n",
        "print(\"Time taken to encode test set in seconds =\", time()-start)\n",
        "print('Extracted Features using VGG16: ', len(features_test))\n",
        "# Dumping the features in a pickle file for further use\n",
        "dump(features_test, open('features_test.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken to encode test set in seconds = 4437.802843332291\n",
            "Extracted Features using VGG16:  7750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inr-uvmpnoMZ",
        "outputId": "8079c92c-352a-48d7-8272-bba5cfd5573e"
      },
      "source": [
        "directory_train = 'ImageCap_Data/VizWiz_Data_train1/train1'\n",
        "model_names = [\"VGG16\",\"InceptionV3\"] \n",
        "\n",
        "start = time()\n",
        "features_train = extract_features(directory_train,model_names[1])\n",
        "print(\"Time taken to encode train set in seconds =\", time()-start)\n",
        "print('Extracted Features using InceptionV3: ', len(features_train))\n",
        "\n",
        "start = time()\n",
        "features_test = extract_features(directory_test,model_names[1])\n",
        "print(\"Time taken to encode test set in seconds =\", time()-start)\n",
        "dump(features_train, open('features_train_Inception.pkl', 'wb'))\n",
        "\n",
        "#print('Extracted Features using VGG16: ', len(features))\n",
        "print('Extracted Features using InceptionV3: ', len(features_train))\n",
        "\n",
        "# Dumping the features in a pickle file for further use\n",
        "dump(features_test, open('features_test_Inception.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 149, 149, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 149, 149, 32) 96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 149, 149, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 147, 147, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 147, 147, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 147, 147, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 147, 147, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 147, 147, 64) 192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 147, 147, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 73, 73, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 73, 73, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 71, 71, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 71, 71, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 71, 71, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 35, 35, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 35, 35, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 35, 35, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 35, 35, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 35, 35, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 35, 35, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 35, 35, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 35, 35, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 35, 35, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 35, 35, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 35, 35, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 35, 35, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 35, 35, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 35, 35, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 35, 35, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 35, 35, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 35, 35, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 35, 35, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 35, 35, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 35, 35, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 35, 35, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 35, 35, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 35, 35, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 35, 35, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 35, 35, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 35, 35, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 35, 35, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 35, 35, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 35, 35, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 35, 35, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 35, 35, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 35, 35, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 35, 35, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 35, 35, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 35, 35, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 35, 35, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 35, 35, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 35, 35, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 35, 35, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 35, 35, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 35, 35, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 35, 35, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 384)  1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 128)  384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 192)  576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 160)  480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 160)  480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 17, 17, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 17, 17, 192)  576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 17, 17, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 17, 17, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken to encode train set in seconds = 5489.989305496216\n",
            "Extracted Features using InceptionV3:  8000\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 149, 149, 32) 864         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 149, 149, 32) 96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 147, 147, 32) 96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 147, 147, 64) 192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 73, 73, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 71, 71, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 35, 35, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 35, 35, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 35, 35, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 35, 35, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 35, 35, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 35, 35, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 35, 35, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 35, 35, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 35, 35, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 35, 35, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 35, 35, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 35, 35, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 35, 35, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 35, 35, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 35, 35, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 35, 35, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 17, 17, 384)  1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 17, 17, 96)   288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 17, 17, 128)  384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 17, 17, 192)  576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 17, 17, 192)  576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 17, 17, 160)  480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 17, 17, 160)  480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 17, 17, 192)  576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 17, 17, 160)  480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 17, 17, 160)  480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 17, 17, 192)  576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 8, 8, 320)    960         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 448)    1344        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 384)    1152        conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 8, 8, 320)    960         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 192)    576         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 448)    1344        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 320)    960         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 192)    576         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken to encode test set in seconds = 1352.5021405220032\n",
            "Extracted Features using InceptionV3:  8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLe3Nhs8wSsp"
      },
      "source": [
        "## Function to map descriptions to images \n",
        "def photo_to_description_mapping(descriptions):\n",
        "    \n",
        "    # Dictionary to store the mapping of photo identifiers to descriptions\n",
        "    description_mapping = dict()\n",
        "    \n",
        "    # Iterating through each line of the descriptions\n",
        "    for line in descriptions.split('\\n'):\n",
        "        \n",
        "        # Splitting the lines by white space\n",
        "        words = line.split()\n",
        "        \n",
        "        # Skipping the lines with length less than 2\n",
        "        if len(line)<2:\n",
        "            continue\n",
        "            \n",
        "        # The first word is the image_id and the rest are the part of the description of that image\n",
        "        image_id, image_description = words[0], words[1:]\n",
        "        \n",
        "        # Retaining only the name of the image and removing the extension from it\n",
        "        image_id = image_id.split('.')[0]\n",
        "        \n",
        "        # Image_descriptions contains comma separated words of the description, hence, converting it back to string\n",
        "        image_description = ' '.join(image_description)\n",
        "                # There are multiple descriptions per image, \n",
        "        # hence, corresponding to every image identifier in the dictionary, there is a list of description\n",
        "        # if the list does not exist then we need to create it\n",
        "        \n",
        "        if image_id not in description_mapping:\n",
        "            description_mapping[image_id] = list()\n",
        "            \n",
        "        # Now storing the descriptions in the mapping\n",
        "        description_mapping[image_id].append(image_description)\n",
        "    \n",
        "    return description_mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShDQ-bhuwr31"
      },
      "source": [
        "\"\"\"\n",
        "Function to clean the descriptions in the following ways:\n",
        "\n",
        "Convert all words to lowercase.\n",
        "Remove all punctuation.\n",
        "Remove all words that are one character or less in length (e.g. ‘a’).\n",
        "Remove all words with numbers in them.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean_descriptions(description_mapping):\n",
        "    \n",
        "    # Preapring a translation table for removing all the punctuation\n",
        "    table = str.maketrans('','', string.punctuation)\n",
        "    \n",
        "    # Traversing through the mapping we created\n",
        "    for key, descriptions in description_mapping.items():\n",
        "        for i in range(len(descriptions)):\n",
        "            description = descriptions[i]\n",
        "            description = description.split()\n",
        "            \n",
        "            # Converting all the words to lower case\n",
        "            description = [word.lower() for word in description]\n",
        "            \n",
        "            # Removing the punctuation using the translation table we made\n",
        "            description = [word.translate(table) for word in description]\n",
        "            \n",
        "            # Removing the words with length =1\n",
        "            description = [word for word in description if len(word)>1]\n",
        "            \n",
        "            # Removing all words with number in them\n",
        "            description = [word for word in description if word.isalpha()]\n",
        "            \n",
        "            # Converting the description back to string and overwriting in the descriptions list\n",
        "            descriptions[i] = ' '.join(description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrDXBPzczDEI"
      },
      "source": [
        "def to_vocabulary(descriptions):\n",
        "    \n",
        "    # Build a list of all description strings\n",
        "    all_desc = set()\n",
        "    \n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
        "    \n",
        "    return all_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGIj7RHRzJDi"
      },
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_descriptions(descriptions, filename):\n",
        "    lines = list()\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + ' ' + desc)\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename, 'w')\n",
        "    file.write(data)\n",
        "    file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkLi5XXOzKBi",
        "outputId": "5f7d26cf-cace-4d1f-f233-6653ea102a31"
      },
      "source": [
        "filename = 'ImageCap_Data/VizWiz_Data_train1/annotations2.txt'\n",
        "\n",
        "# Loading descriptions\n",
        "doc = load_doc(filename)\n",
        "\n",
        "# Parsing descriptions\n",
        "descriptions = photo_to_description_mapping(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "\n",
        "# Cleaning the descriptions\n",
        "clean_descriptions(descriptions)\n",
        "\n",
        "# Summarizing the vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "\n",
        "# Saving to the file\n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8000 \n",
            "Vocabulary Size: 10929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kMIBv5p1MgK"
      },
      "source": [
        "# Function for loading a file into memory and returning text from it\n",
        "def load_file(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Function for loading a pre-defined list of photo identifiers\n",
        "def load_photo_identifiers(filename):\n",
        "    \n",
        "    # Loading the file containing the list of photo identifier\n",
        "    file = load_file(filename)\n",
        "    \n",
        "    # Creating a list for storing the identifiers\n",
        "    photos = list()\n",
        "    \n",
        "    # Traversing the file one line at a time\n",
        "    for line in file.split('\\n'):\n",
        "        if len(line) < 1:\n",
        "            continue\n",
        "        \n",
        "        # Image name contains the extension as well but we need just the name\n",
        "        identifier = line.split('.')[0]\n",
        "        \n",
        "        # Adding it to the list of photos\n",
        "        photos.append(identifier)\n",
        "    # Returning the set of photos created\n",
        "    return set(photos)\n",
        "\n",
        "\n",
        "# loading the cleaned descriptions that we created earlier\n",
        "# we will only be loading the descriptions of the images that we will use for training\n",
        "# hence we need to pass the set of train photos that the above function will be returning\n",
        "\n",
        "def load_clean_descriptions(filename, photos):\n",
        "    \n",
        "    #loading the cleaned description file\n",
        "    file = load_file(filename)\n",
        "    \n",
        "    #creating a dictionary of descripitions for storing the photo to description mapping of train images\n",
        "    descriptions = dict()\n",
        "    \n",
        "    #traversing the file line by line\n",
        "    for line in file.split('\\n'):\n",
        "        # splitting the line at white spaces\n",
        "        words = line.split()\n",
        "        \n",
        "        # the first word will be the image name and the rest will be the description of that particular image\n",
        "        image_id, image_description = words[0], words[1:]\n",
        "        \n",
        "        # we want to load only those description which corresponds to the set of photos we provided as argument\n",
        "        if image_id in photos:\n",
        "            #creating list of description if needed\n",
        "            if image_id not in descriptions:\n",
        "                descriptions[image_id] = list()\n",
        "            #the model we will develop will generate a caption given a photo, \n",
        "            #and the caption will be generated one word at a time. \n",
        "            #The sequence of previously generated words will be provided as input. \n",
        "            #Therefore, we will need a ‘first word’ to kick-off the generation process \n",
        "            #and a ‘last word‘ to signal the end of the caption.\n",
        "            #we will use 'startseq' and 'endseq' for this purpose\n",
        "            #also we have to convert image description back to string\n",
        "            \n",
        "            desc = 'startseq ' + ' '.join(image_description) + ' endseq'\n",
        "            descriptions[image_id].append(desc)\n",
        "            \n",
        "    return descriptions\n",
        "\n",
        "# function to load the photo features created using the VGG16 model\n",
        "def load_photo_features(filename, photos):\n",
        "    \n",
        "    #this will load the entire features\n",
        "    all_features = load(open(filename, 'rb'))\n",
        "    \n",
        "    #we are interested in loading the features of the required photos only\n",
        "    features = {k: all_features[k] for k in photos}\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chyihH2V1e8C",
        "outputId": "044c6279-79c5-4894-de09-3935f9b9361e"
      },
      "source": [
        "filename = 'ImageCap_Data/VizWiz_Data_train1/annotations2.txt'\n",
        "train = load_photo_identifiers(filename)\n",
        "print('Dataset: ',len(train))\n",
        "\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=', len(train_descriptions))\n",
        "\n",
        "train_features = load_photo_features('features_train.pkl', train)\n",
        "print('Photos: train=', len(train_features))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset:  8000\n",
            "Descriptions: train= 8000\n",
            "Photos: train= 8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVxWywhS1_q1"
      },
      "source": [
        "# convert a dictionary of clean descriptions to a list of descriptions\n",
        "def to_lines(descriptions):\n",
        "    all_desc = list()\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc\n",
        "\n",
        "# Given the descriptions, fit a tokenizer\n",
        "\n",
        "# TOKENIZER CLASS:\n",
        "# This class allows to vectorize a text corpus, \n",
        "# by turning each text into either a sequence of integers \n",
        "# (each integer being the index of a token in a dictionary) \n",
        "# or, into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2hvBOoz2DtO",
        "outputId": "e2974d08-7ff6-4843-8ff4-825f4599c49e"
      },
      "source": [
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: ', vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  10932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pllFovZG2KSZ"
      },
      "source": [
        "#calculated the length of description with most words\n",
        "def max_lengthTEMP(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    return max(len(d.split()) for d in lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G6DJM0e2P31"
      },
      "source": [
        "#the below function loop forever with a while loop and within this, \n",
        "#loop over each image in the image directory. \n",
        "#For each image filename, we can load the image and \n",
        "#create all of the input-output sequence pairs from the image’s description.\n",
        "\n",
        "#data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(descriptions, photos, tokenizer, max_length):\n",
        "    while 1:\n",
        "        for key, description_list in descriptions.items():\n",
        "            #retrieve photo features\n",
        "            photo = photos[key][0]\n",
        "            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, photo)\n",
        "            yield [input_image, input_sequence], output_word\n",
        "#we are calling the create_sequence() function to create \n",
        "#a batch worth of data for a single photo rather than an entire dataset. \n",
        "#This means that we must update the create_sequences() function \n",
        "#to delete the “iterate over all descriptions” for-loop.            \n",
        "#Updated create sequence function for data_generator\n",
        "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    # walk through each description for the image\n",
        "    for desc in desc_list:\n",
        "        # encode the sequence\n",
        "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "        # split one sequence into multiple X,y pairs\n",
        "        for i in range(1, len(seq)):\n",
        "            # split into input and output pair\n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            # pad input sequence\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            # encode output sequence\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "            # store\n",
        "            X1.append(photo)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    return array(X1), array(X2), array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCZ7uQR2Ywr"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "    \n",
        "    # feature extractor model\n",
        "    inputs1 = Input(shape=(4096,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "    # sequence model\n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    se3 = LSTM(256)(se2)\n",
        "\n",
        "    # decoder model\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "    \n",
        "    # tie it together [image, seq] [word]\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    # summarize model\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h37JwhAK2lcV",
        "outputId": "515fc612-3e65-41bb-c73d-212769f41896"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/DeepLearning\n",
        "filename = 'ImageCap_Data/VizWiz_Data_train1/annotations2.txt'\n",
        "train = load_photo_identifiers(filename)\n",
        "print('Dataset: ', len(train))\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=', len(train_descriptions))\n",
        "train_features = load_photo_features('features_train.pkl', train)\n",
        "print('Photos: train=', len(train_features))\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "max_length = max_lengthTEMP(train_descriptions)\n",
        "print('Description Length: ', max_length)\n",
        "\n",
        "%cd /content/gdrive/MyDrive/DeepLearning/ImageCap_Data\n",
        "model = define_model(vocab_size, max_length)\n",
        "epochs = 20\n",
        "steps = len(train_descriptions)\n",
        "for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('model_' + str(i) + '.h5')\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/DeepLearning\n",
            "Dataset:  8000\n",
            "Descriptions: train= 8000\n",
            "Photos: train= 8000\n",
            "Vocabulary Size: 10932\n",
            "Description Length:  80\n",
            "/content/gdrive/MyDrive/DeepLearning/ImageCap_Data\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 4096)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 80, 256)      2798592     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 4096)         0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 80, 256)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          1048832     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          525312      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10932)        2809524     dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,248,052\n",
            "Trainable params: 7,248,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 1435s 179ms/step - loss: 5.1504\n",
            "8000/8000 [==============================] - 1427s 178ms/step - loss: 4.0585\n",
            "8000/8000 [==============================] - 1425s 178ms/step - loss: 3.8338\n",
            "8000/8000 [==============================] - 1426s 178ms/step - loss: 3.6883\n",
            "8000/8000 [==============================] - 1423s 178ms/step - loss: 3.6015\n",
            "8000/8000 [==============================] - 1430s 179ms/step - loss: 3.5300\n",
            "8000/8000 [==============================] - 1432s 179ms/step - loss: 3.4746\n",
            "8000/8000 [==============================] - 1437s 180ms/step - loss: 3.4360\n",
            "8000/8000 [==============================] - 1449s 181ms/step - loss: 3.3994\n",
            "8000/8000 [==============================] - 1451s 181ms/step - loss: 3.3762\n",
            "8000/8000 [==============================] - 1426s 178ms/step - loss: 3.3513\n",
            "8000/8000 [==============================] - 1424s 178ms/step - loss: 3.3289\n",
            "8000/8000 [==============================] - 1427s 178ms/step - loss: 3.3088\n",
            "8000/8000 [==============================] - 1428s 179ms/step - loss: 3.2991\n",
            "8000/8000 [==============================] - 1428s 179ms/step - loss: 3.3005\n",
            "8000/8000 [==============================] - 1429s 179ms/step - loss: 3.2827\n",
            "8000/8000 [==============================] - 1430s 179ms/step - loss: 3.2732\n",
            "8000/8000 [==============================] - 1431s 179ms/step - loss: 3.2654\n",
            "8000/8000 [==============================] - 1431s 179ms/step - loss: 3.2638\n",
            "8000/8000 [==============================] - 1433s 179ms/step - loss: 3.2592\n",
            "/content/gdrive/My Drive/DeepLearning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0j_UBpbhqzG"
      },
      "source": [
        "##Part2\n",
        "Inception V3 for ecoding and pretrained glove embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A0x78t7kwFN",
        "outputId": "35592957-f3aa-4111-8cb6-8cc93938a4fd"
      },
      "source": [
        "# Create a list of all the training captions\n",
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)\n",
        "len(all_train_captions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlnWrW1elFoc",
        "outputId": "32f4ea84-d4b0-445c-bc0b-3f95b7cb39e0"
      },
      "source": [
        "def to_vocabulary(descriptions):\n",
        "    \n",
        "    # Build a list of all description strings\n",
        "    all_desc = set()\n",
        "    \n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
        "    \n",
        "    return all_desc\n",
        "#Consider only words which occur at least 10 times in the corpus\n",
        "word_count_threshold = 10\n",
        "word_counts = {}\n",
        "nsents = 0\n",
        "for sent in all_train_captions:\n",
        "    nsents += 1\n",
        "    for w in sent.split(' '):\n",
        "        word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessed words 10932 -> 2481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhaT5EclP69"
      },
      "source": [
        "ixtoword = {}\n",
        "wordtoix = {}\n",
        "\n",
        "ix = 1\n",
        "for w in vocab:\n",
        "    wordtoix[w] = ix\n",
        "    ixtoword[ix] = w\n",
        "    ix += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfz03CrblTML",
        "outputId": "cdfd3402-af92-4670-e45b-2268bb343852"
      },
      "source": [
        "vocab_size = len(ixtoword) + 1 # one for appended 0's\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JruIY1dllVT",
        "outputId": "e0195673-f426-4521-88fe-cff8db3a91da"
      },
      "source": [
        "# convert a dictionary of clean descriptions to a list of descriptions\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# calculate the length of the description with the most words\n",
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "\n",
        "# determine the maximum sequence length\n",
        "max_length = max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Description Length: 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7ZCXymh8y1"
      },
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator_(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n=0\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            n+=1\n",
        "            # retrieve the photo feature\n",
        "            photo = photos[key][0]\n",
        "            for desc in desc_list:\n",
        "                # encode the sequence\n",
        "                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence\n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "                    # store\n",
        "                    X1.append(photo)\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "            # yield the batch data\n",
        "            if n==num_photos_per_batch:\n",
        "                yield [array(X1), array(X2)], array(y)\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tblM5PXQfWDo",
        "outputId": "b6e223e2-08cf-4ee6-f086-be4d6f33f2e0"
      },
      "source": [
        "# Load Glove vectors\n",
        "glove_dir = 'ImageCap_Data/glove.6B.200d.txt'\n",
        "embeddings_index = {} # empty dictionary\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnwxhQ3HfvmZ"
      },
      "source": [
        "\n",
        "embedding_dim = 200\n",
        "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in wordtoix.items():\n",
        "    #if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in the embedding index will be all zeros\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY4UkbKnelOV"
      },
      "source": [
        "##Using pretrained glove embedding weights \n",
        "#And inception v3 ecoded features\n",
        "\n",
        "from keras.utils import plot_model\n",
        "# define the captioning model\n",
        "def define_model_(vocab_size, max_length,num_layers,nodes):\n",
        "    \n",
        "    # feature extractor model\n",
        "    inputs1 = Input(shape=(2048,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(nodes, activation='relu')(fe1)\n",
        "\n",
        "    # sequence model\n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, embedding_dim, mask_zero=True, name='embedding')(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    if num_layers == 2 : \n",
        "      se4 = LSTM(nodes, return_sequences=True)(se2)\n",
        "      se3 = LSTM(nodes)(se4)\n",
        "\n",
        "    elif num_layers == 3 : \n",
        "      se5 = LSTM(nodes, return_sequences=True)(se2)\n",
        "      se4 = LSTM(nodes, return_sequences=True)(se5)\n",
        "      se3 = LSTM(nodes)(se4)\n",
        "  \n",
        "    else:\n",
        "      se3 = LSTM(nodes)(se2)\n",
        "\n",
        "    # decoder model\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(nodes, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "    \n",
        "    # tie it together [image, seq] [word]\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    # summarize model\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='model_inceptionv.png', show_shapes=True)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpM4Ilt7gi57",
        "outputId": "95dbfa14-8394-4223-99fb-9668cfcc535a"
      },
      "source": [
        "num_layers = 2 ## Choices between 1,2 or 3 LSTMS\n",
        "nodes = 256\n",
        "\n",
        "model_1 = define_model_(vocab_size, max_length, num_layers,nodes)\n",
        "\n",
        "for i,layer in enumerate(model_1.layers):\n",
        "  if layer.name == 'embedding':\n",
        "    model_1.layers[i].set_weights([embedding_matrix])\n",
        "    model_1.layers[i].trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_64\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_136 (InputLayer)          [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 200)      496400      input_136[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_135 (InputLayer)          [(None, 2048)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 80, 200)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 2048)         0           input_135[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_147 (LSTM)                 (None, 80, 256)      467968      dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_195 (Dense)               (None, 256)          524544      dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_148 (LSTM)                 (None, 256)          525312      lstm_147[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 256)          0           dense_195[0][0]                  \n",
            "                                                                 lstm_148[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_196 (Dense)               (None, 256)          65792       add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_197 (Dense)               (None, 2482)         637874      dense_196[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,717,890\n",
            "Trainable params: 2,717,890\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scAQFIRTgv_h"
      },
      "source": [
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMDVsLGphB61",
        "outputId": "aa31756e-35d5-4941-9e33-f412e8fd3e14"
      },
      "source": [
        "epochs = 20\n",
        "number_pics_per_bath = 20\n",
        "steps = len(train_descriptions)//number_pics_per_bath\n",
        "\n",
        "train_features = load_photo_features('features_train_Inception.pkl', train)\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "for i in range(epochs):\n",
        "    generator = data_generator_(train_descriptions, train_features, wordtoix, max_length, number_pics_per_bath)\n",
        "    model_1.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model_1.save('ImageCap_Data/model_2lstms_' + str(i) + '.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400/400 [==============================] - 150s 360ms/step - loss: 5.8288\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 4.2687\n",
            "400/400 [==============================] - 144s 361ms/step - loss: 3.9661\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 3.7913\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.6741\n",
            "400/400 [==============================] - 144s 361ms/step - loss: 3.5823\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.5093\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 3.4486\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 3.3926\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.3439\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 3.3011\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.2547\n",
            "400/400 [==============================] - 144s 361ms/step - loss: 3.2169\n",
            "400/400 [==============================] - 145s 363ms/step - loss: 3.1834\n",
            "400/400 [==============================] - 144s 359ms/step - loss: 3.1506\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.1160\n",
            "400/400 [==============================] - 144s 361ms/step - loss: 3.0811\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.0476\n",
            "400/400 [==============================] - 145s 361ms/step - loss: 3.0210\n",
            "400/400 [==============================] - 144s 360ms/step - loss: 3.0023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVOQ-CMrnz5e"
      },
      "source": [
        "model_1.optimizer.lr = 0.0001\n",
        "epochs = 10\n",
        "number_pics_per_bath = 40\n",
        "steps = len(train_descriptions)//number_pics_per_bath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWfnN7bXn4L2",
        "outputId": "a963706b-8858-4673-c364-116c776578a8"
      },
      "source": [
        "for i in range(epochs):\n",
        "    generator = data_generator_(train_descriptions, train_features, wordtoix, max_length, number_pics_per_bath)\n",
        "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('ImageCap_Data/model_2lstms_' + str(i+20) + '.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 100s 475ms/step - loss: 2.9740\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 2.9520\n",
            "200/200 [==============================] - 95s 473ms/step - loss: 2.9332\n",
            "200/200 [==============================] - 95s 473ms/step - loss: 2.9151\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 2.8987\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 2.8796\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 2.8623\n",
            "200/200 [==============================] - 94s 472ms/step - loss: 2.8446\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 2.8322\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 2.8155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uBJtgbeoTX_"
      },
      "source": [
        "##Evaluation\n",
        "\n",
        "First we evaluate the VGG feature extracted model without word count threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALha-3i0oRvn"
      },
      "source": [
        "## VGG without wordcount threshold\n",
        "#this function maps an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "#The function below generates a textual description given a trained model, \n",
        "#and a given prepared photo as input. It calls the function word_for_id() \n",
        "#in order to map an integer prediction back to a word.\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    #start tge generation process\n",
        "    in_text = 'startseq'\n",
        "    #iterating over the max_length since the maximum length of the description can be that only\n",
        "    for i in range(max_length):\n",
        "        #integer ncoding input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        #padding the input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        #predicting next word\n",
        "        #the predict function will return probability\n",
        "        prob = model.predict([photo,sequence], verbose=0)\n",
        "        #converting the probability to integer\n",
        "        prob = argmax(prob)\n",
        "        #calling the word_for_id function in order to map integer to word\n",
        "        word = word_for_id(prob, tokenizer)\n",
        "        #breaking if word cannot be mapped\n",
        "        if word is None:\n",
        "            break\n",
        "        #appending as input\n",
        "        in_text += ' ' + word\n",
        "        #break if end is predicted\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "\n",
        "\n",
        "#the below function evaluates the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "    actual, predicted = list(), list()\n",
        "    features = dict()\n",
        "    bar = progressbar.ProgressBar(maxval=len(descriptions), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        "    i=0\n",
        "    for key, desc_list in descriptions.items():\n",
        "        prediction = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "        actual_desc = [d.split() for d in desc_list]\n",
        "        actual.append(actual_desc)\n",
        "        predicted.append(prediction.split())\n",
        "        bar.update(i+1)\n",
        "        sleep(0.01)\n",
        "        i += 1\n",
        "    bar.finish()\n",
        "    print('BLEU-1: ', corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: ', corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: ', corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: ', corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "    \n",
        "def max_length(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    return max(len(d.split()) for d in lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRtMG-e4VY1T"
      },
      "source": [
        "This funtion is used to evaluate the Inception models with word count threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoyMVF9qOpS8"
      },
      "source": [
        "#The function below generates a textual description given a trained model, \n",
        "#and a given prepared photo as input. It calls the function word_for_id() \n",
        "#in order to map an integer prediction back to a word.\n",
        "def generate_desc_(model, wordtoix, photo, max_length):\n",
        "    #start tge generation process\n",
        "    in_text = 'startseq'\n",
        "    #iterating over the max_length since the maximum length of the description can be that only\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = ixtoword[yhat]\n",
        "        in_text += ' ' + word\n",
        "        if word is None:\n",
        "            break\n",
        "        #appending as input\n",
        "        in_text += ' ' + word\n",
        "        #break if end is predicted\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "\n",
        "#the below function evaluates the skill of the model\n",
        "def evaluate_model_(model, descriptions, photos, wordtoix, max_length):\n",
        "    actual, predicted = list(), list()\n",
        "    features = dict()\n",
        "    bar = progressbar.ProgressBar(maxval=len(descriptions), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        "    i=0\n",
        "    for key, desc_list in descriptions.items():\n",
        "        prediction = generate_desc_(model, wordtoix, photos[key], max_length)\n",
        "        actual_desc = [d.split() for d in desc_list]\n",
        "        actual.append(actual_desc)\n",
        "        predicted.append(prediction.split())\n",
        "        bar.update(i+1)\n",
        "        sleep(0.01)\n",
        "        i += 1\n",
        "    bar.finish()\n",
        "    print('BLEU-1: ', corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: ', corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: ', corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: ', corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "    \n",
        "def max_length(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    return max(len(d.split()) for d in lines)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmJhRt89qq9p",
        "outputId": "303a5ccc-e624-4abf-a8ec-2d190362f3c9"
      },
      "source": [
        "##Prepare test descriptions from annotations\n",
        "filename = 'ImageCap_Data/VizWiz_Data_val/annotations_val2.txt'\n",
        "\n",
        "# Loading descriptions\n",
        "doc = load_doc(filename)\n",
        "\n",
        "# Parsing descriptions\n",
        "descriptions = photo_to_description_mapping(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "\n",
        "# Cleaning the descriptions\n",
        "clean_descriptions(descriptions)\n",
        "\n",
        "# Summarizing the vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "\n",
        "# Saving to the file\n",
        "save_descriptions(descriptions, 'descriptions_test.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 7750 \n",
            "Vocabulary Size: 10911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV7OK0jaVu7j"
      },
      "source": [
        "VGG Evaluation section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcCyDokqoy91",
        "outputId": "fc62d5c8-01fa-4e27-af8e-840758c022b5"
      },
      "source": [
        "filename = 'ImageCap_Data/VizWiz_Data_train1/annotations2.txt'\n",
        "train = load_photo_identifiers(filename)\n",
        "print('Dataset: ', len(train))\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=', len(train_descriptions))\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: ', vocab_size)\n",
        "max_length = max_lengthTEMP(train_descriptions)\n",
        "print('Description Length: ,', max_length)\n",
        "\n",
        "filename = 'ImageCap_Data/VizWiz_Data_val/annotations_val2.txt'\n",
        "test = load_photo_identifiers(filename)\n",
        "print('Dataset: ', len(test))\n",
        "test_descriptions = load_clean_descriptions('descriptions_test.txt', test)\n",
        "print('Descriptions: test=', len(test_descriptions))\n",
        "test_features = load_photo_features('features_test.pkl', test)\n",
        "print('Photos: test=', len(test_features))\n",
        "\n",
        "filename = 'ImageCap_Data/model_19.h5'\n",
        "model = load_model(filename)\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset:  8000\n",
            "Descriptions: train= 8000\n",
            "Vocabulary Size:  10932\n",
            "Description Length: , 80\n",
            "Dataset:  7750\n",
            "Descriptions: test= 7750\n",
            "Photos: test= 7750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1:  0.5117146174687137\n",
            "BLEU-2:  0.40917261050548287\n",
            "BLEU-3:  0.4157560166538293\n",
            "BLEU-4:  0.36088472361135443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvcpbGmhV-mY"
      },
      "source": [
        "Inception Models evaluation section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJauYFc8Wa0d",
        "outputId": "4557b842-e44e-4f68-ee9c-8faa64876bda"
      },
      "source": [
        "##Prepare test descriptions from annotations\n",
        "filename = 'ImageCap_Data/VizWiz_Data_val/annotations_val2.txt'\n",
        "\n",
        "# Loading descriptions\n",
        "doc = load_doc(filename)\n",
        "\n",
        "# Parsing descriptions\n",
        "descriptions = photo_to_description_mapping(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "\n",
        "# Cleaning the descriptions\n",
        "clean_descriptions(descriptions)\n",
        "\n",
        "# Summarizing the vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "# Saving to the file\n",
        "save_descriptions(descriptions, 'descriptions_test.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 7750 \n",
            "Vocabulary Size: 10911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKRxf6U9y9hb",
        "outputId": "9e221d77-e6d5-4ea8-f837-ba1bc3298f6c"
      },
      "source": [
        "max_length = max_lengthTEMP(train_descriptions)\n",
        "print('Description Length: ,', max_length)\n",
        "\n",
        "filename = 'ImageCap_Data/VizWiz_Data_val/annotations_val2.txt'\n",
        "test = load_photo_identifiers(filename)\n",
        "print('Test Dataset Sample size: ', len(test))\n",
        "\n",
        "test_descriptions = load_clean_descriptions('descriptions_test.txt', test)\n",
        "print('Descriptions: test=', len(test_descriptions))\n",
        "\n",
        "test_features = load_photo_features('features_test_Inception.pkl', test)\n",
        "print('Photos: test=', len(test_features))\n",
        "\n",
        "filename = 'ImageCap_Data/model_inception_19.h5'\n",
        "model = load_model(filename)\n",
        "evaluate_model_(model, test_descriptions, test_features, wordtoix, max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Dataset Sample size:  7750\n",
            "Descriptions: test= 7750\n",
            "Photos: test= 7750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1:  0.31910673976136733\n",
            "BLEU-2:  0.1889014465377576\n",
            "BLEU-3:  0.011351786774561617\n",
            "BLEU-4:  0.023945294761807685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxl4m1H7y_At",
        "outputId": "7e05bb8c-dd72-446a-b96d-942e3dc16127"
      },
      "source": [
        "max_length = max_lengthTEMP(train_descriptions)\n",
        "print('Description Length: ,', max_length)\n",
        "\n",
        "filename = 'ImageCap_Data/VizWiz_Data_val/annotations_val2.txt'\n",
        "test = load_photo_identifiers(filename)\n",
        "print('Test Dataset Sample size: ', len(test))\n",
        "\n",
        "test_descriptions = load_clean_descriptions('descriptions_test.txt', test)\n",
        "print('Descriptions: test=', len(test_descriptions))\n",
        "\n",
        "test_features = load_photo_features('features_test_Inception.pkl', test)\n",
        "print('Photos: test=', len(test_features))\n",
        "filename = 'ImageCap_Data/model_2lstms_29.h5'\n",
        "model = load_model(filename)\n",
        "evaluate_model_(model, test_descriptions, test_features, wordtoix, max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Description Length: , 80\n",
            "Test Dataset Sample size:  7750\n",
            "Descriptions: test= 7750\n",
            "Photos: test= 7750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1:  0.2717151127935458\n",
            "BLEU-2:  0.1774838819182673\n",
            "BLEU-3:  0.35440133682794844\n",
            "BLEU-4:  0.4212883595807832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLGG6OMZ1uL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_loss(loss_file):\n",
        "  file = loss_file\n",
        "  loss_file = load_doc(file)\n",
        "  losses = []\n",
        "  for line in loss_file.split('\\n'):\n",
        "    loss = line.split(' ')\n",
        "    if loss[-1] != '' :\n",
        "      losses.append(float(loss[-1]))\n",
        "  x_axis = []\n",
        "  for i in range(len(losses)):\n",
        "    x_axis.append(i+1)\n",
        "\n",
        "  plt.plot(x_axis,losses)\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "o9z9TndqZ4GA",
        "outputId": "5970056f-9eba-40d2-d9c3-57d4f062b4a8"
      },
      "source": [
        "file = \"ImageCap_Data/loss_VGG.txt\"\n",
        "plot_loss(file) \n",
        "\n",
        "file = \"ImageCap_Data/loss.txt\"\n",
        "plot_loss(file)\n",
        "\n",
        "file = \"ImageCap_Data/loss_2lstm.txt\"\n",
        "plot_loss(file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcdZ3/8ddnZpJM0lzbpkl6I5ZbuVNoq1AV5KLIVVkEVFBQFhFdUVxX8ef6c3msu+7qiq6giFwsCwrIbQFBBCnItSUt5doWCrT0ljZtmubS5v7ZP85JO8S0BJrJyeS8n49HHjNzzpmZz+k08873e875fs3dERGR+EpEXYCIiERLQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIJBYMbPfmtm/DnLbFWZ2XLZrEomagkBEJOYUBCI5yMxSUdcgo4eCQEacsEvmW2b2gpm1mdl1ZlZlZg+YWYuZPWxmFRnbn2pmL5tZk5k9amb7ZaybYWaLwufdCqT7vdfJZrY4fO5TZnbwIGs8ycyeM7NmM1tlZj/ot/6D4es1hevPC5cXmtl/mdlKM9tiZk+Ey442s9UD/DscF97/gZndbmY3mVkzcJ6ZzTazp8P3WGdmV5pZfsbzDzCzh8ys0czWm9l3zazazLaa2biM7Q4zswYzyxvMvsvooyCQkervgOOBfYBTgAeA7wKVBP9vvwZgZvsAvwe+Hq67H7jXzPLDL8W7gf8BxgJ/CF+X8LkzgOuBLwHjgF8D95hZwSDqawM+B5QDJwFfNrNPhK+7R1jvL8KaDgUWh8/7CXA4cGRY0z8BvYP8NzkNuD18z5uBHuAbwHjgCOBY4OKwhhLgYeBPwERgL+Av7l4PPAqcmfG65wK3uHvXIOuQUUZBICPVL9x9vbuvAR4H5rv7c+7eDtwFzAi3Owv4o7s/FH6R/QQoJPii/QCQB/zM3bvc/Xbg2Yz3uBD4tbvPd/ced58LdITP2yV3f9TdX3T3Xnd/gSCMjgpXfwZ42N1/H77vJndfbGYJ4AvAJe6+JnzPp9y9Y5D/Jk+7+93he25z94Xu/oy7d7v7CoIg66vhZKDe3f/L3dvdvcXd54fr5gLnAJhZEvg0QVhKTCkIZKRan3F/2wCPi8P7E4GVfSvcvRdYBUwK163xt4+suDLj/h7AN8OulSYzawKmhM/bJTN7v5nNC7tUtgAXEfxlTvgarw/wtPEEXVMDrRuMVf1q2MfM7jOz+rC76N8GUQPA/wL7m9n7CFpdW9x9wXusSUYBBYHkurUEX+gAmJkRfAmuAdYBk8JlfaZm3F8F/NDdyzN+itz994N4398B9wBT3L0MuBroe59VwJ4DPGcj0L6TdW1AUcZ+JAm6lTL1Hyr4V8BSYG93LyXoOsusYdpAhYetqtsIWgXnotZA7CkIJNfdBpxkZseGBzu/SdC98xTwNNANfM3M8szsdGB2xnN/A1wU/nVvZjYmPAhcMoj3LQEa3b3dzGYTdAf1uRk4zszONLOUmY0zs0PD1sr1wE/NbKKZJc3siPCYxKtAOnz/POB7wDsdqygBmoFWM5sOfDlj3X1AjZl93cwKzKzEzN6fsf5G4DzgVBQEsacgkJzm7ssI/rL9BcFf3KcAp7h7p7t3AqcTfOE1EhxPuDPjuXXA3wNXApuB5eG2g3ExcLmZtQDfJwikvtd9CziRIJQaCQ4UHxKu/kfgRYJjFY3AfwAJd98Svua1BK2ZNuBtZxEN4B8JAqiFINRuzaihhaDb5xSgHngN+EjG+icJDlIvcvfM7jKJIdPENCLxZGaPAL9z92ujrkWipSAQiSEzmwU8RHCMoyXqeiRa6hoSiRkzm0twjcHXFQICahGIiMSeWgQiIjGXcwNXjR8/3mtra6MuQ0QkpyxcuHCju/e/NgXIwSCora2lrq4u6jJERHKKme30NGF1DYmIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICISc7EJgmX1Lfznn5ayZaumZRURyRSbIFi5qY1fPvo6bzVujboUEZERJTZBUF2WBqC+uT3iSkRERpb4BcGWbRFXIiIyssQmCMaPKSCVMLUIRET6iU0QJBJGVWmadVsUBCIimWITBABVpQWsV4tARORtYhUENWWFahGIiPQTqyCoKk1Tv6UdTc8pIrJDrIKgpizN1s4eWjq6oy5FRGTEiFUQVIWnkK5X95CIyHaxCoKaMAh0nEBEZIdYBUF1qa4uFhHpL1ZBMKG0AIB6tQhERLaLVRAUpJKMG5OvFoGISIZYBQEEYw6pRSAiskP8gqBUQSAikil+QVCWVteQiEiG+AVBaZrGtk7au3qiLkVEZESIXxCE1xJsaO6IuBIRkZEhtkGg7iERkUDsgmDH1cWaqUxEBGIYBFXh1cWal0BEJBC7IChJ51FckNJ4QyIiodgFAWimMhGRTLEMAs1UJiKyQyyDoKo0rTkJRERCsQyCmrI061s66OnVlJUiIlkPAjNLmtlzZnbfAOvOM7MGM1sc/lyQ7XogmKmsp9fZ1KqLykREUsPwHpcAS4DSnay/1d2/Ogx1bFdTumOmsgnhfRGRuMpqi8DMJgMnAddm833eLV1dLCKyQ7a7hn4G/BPQu4tt/s7MXjCz281sykAbmNmFZlZnZnUNDQ27XdT2INABYxGR7AWBmZ0MbHD3hbvY7F6g1t0PBh4C5g60kbtf4+4z3X1mZWXlbtc2tiifvKSpRSAiQnZbBHOAU81sBXALcIyZ3ZS5gbtvcve+I7bXAodnsZ7tEgmjShPUiIgAWQwCd7/M3Se7ey1wNvCIu5+TuY2Z1WQ8PJXgoPKw0ExlIiKB4Thr6G3M7HKgzt3vAb5mZqcC3UAjcN5w1VFdlubltc3D9XYiIiPWsASBuz8KPBre/37G8suAy4ajhv6qS9P8ZckG3B0zi6IEEZERIZZXFkPQItjW1UPztu6oSxERiVSsgwB0LYGISGyDQDOViYgEYhsEmqlMRCQQ2yCYUJLGDM1LICKxF9sgyE8lGDdGM5WJiMQ2CCA4TqAWgYjEXayDQMNMiIjEPAhqytI6fVREYi/WQVBdlqZpaxftXT1RlyIiEpl4B0Gp5iUQEYl3EJTtmLJSRCSuFAToojIRibd4B0GpWgQiIrEOgjEFKUrSKbUIRCTWYh0EELQKNPCciMSZgqAsTX1zxztvKCIySikIStPUq0UgIjEW+yCoKUvT0NJBd09v1KWIiEQi9kFQVZam16GhVd1DIhJPsQ+CvpnKdHWxiMRV7IOgSsNMiEjMxT4IasoKAU1iLyLxFfsgqCjKIz+VUItARGIr9kFgZsEppGoRiEhMxT4IoO/qYgWBiMSTgoDg6mKNNyQicaUgIAiCdVvacfeoSxERGXYKAoKuoc7uXpq2dkVdiojIsFMQoJnKRCTeFARopjIRibesB4GZJc3sOTO7b4B1BWZ2q5ktN7P5Zlab7XoGopnKRCTOhqNFcAmwZCfrvghsdve9gCuA/xiGev5GZUkBCdPVxSIST1kNAjObDJwEXLuTTU4D5ob3bweONTPLZk0DyUsmGF9coHkJRCSWst0i+BnwT8DOBvufBKwCcPduYAswLss1DahGM5WJSExlLQjM7GRgg7svHILXutDM6sysrqGhYQiq+1tVmqlMRGIqmy2COcCpZrYCuAU4xsxu6rfNGmAKgJmlgDJgU/8Xcvdr3H2mu8+srKzMSrE1ZWkNPCcisZS1IHD3y9x9srvXAmcDj7j7Of02uwf4fHj/jHCbSC7vrSpL09zezdbO7ijeXkQkMsN+HYGZXW5mp4YPrwPGmdly4FLgO8NdTx/NVCYicZUajjdx90eBR8P7389Y3g58ajhqeCeZM5VNqyyOuBoRkeGjK4tDmqlMROJKQRDS1cUiElcKglBhfpKywjyNNyQisaMgyKCZykQkjhQEGTRTmYjEkYIgg1oEIhJHCoIM1WVpNrZ20NWzs6GRRERGHwVBhuqyNO6woUWDz4lIfCgIMlTr6mIRiSEFQYbqUgWBiMSPgiDD9vGGdOaQiMSIgiBDWWEeBamE5iUQkVhREGQwM81UJiKxoyDoRzOViUjcKAj6CVoEOkYgIvGhIOinqizN+i0dRDRRmojIsFMQ9FNTmqazp5fGts6oSxERGRaDCgIzu8TMSi1wnZktMrOPZru4KPRdVKYxh0QkLgbbIviCuzcDHwUqgHOBH2WtqghV981UpiAQkZgYbBBYeHsi8D/u/nLGslFl+9XFOmAsIjEx2CBYaGZ/JgiCB82sBBiVQ3RWlhSQTJhaBCISG6lBbvdF4FDgDXffamZjgfOzV1Z0kgmjsriA1Zu3Rl2KiMiwGGyL4Ahgmbs3mdk5wPeALdkrK1pz9hrP/S/Vs6ZJF5aJyOg32CD4FbDVzA4Bvgm8DtyYtaoi9o3j9wbgp39+NeJKRESyb7BB0O3BFVanAVe6+1VASfbKitbkiiLOP7KWO59bzStrm6MuR0QkqwYbBC1mdhnBaaN/NLMEkJe9sqJ38dF7UZrO40d/Whp1KSIiWTXYIDgL6CC4nqAemAz8OGtVjQBlRXn8wzF78ddXG3j8tYaoyxERyZpBBUH45X8zUGZmJwPt7j5qjxH0OfeIPZhcUci/3b+U3l6NPSQio9Ngh5g4E1gAfAo4E5hvZmdks7CRoCCV5Fsf25cl65q5e/GaqMsREcmKwXYN/T9glrt/3t0/B8wG/jl7ZY0cpxw8kYMmlfGTB5fR3tUTdTkiIkNusEGQcPcNGY83vYvn5rREwrjsxOms3dLO3KdWRF2OiMiQG+yX+Z/M7EEzO8/MzgP+CNyfvbJGliP3HM9H9q3kynnL2azhqUVklBnsweJvAdcAB4c/17j7t3f1HDNLm9kCM3vezF42s38ZYJvzzKzBzBaHPxe8l50YDt/5+H60dXRz5bzlUZciIjKkBjvWEO5+B3DHu3jtDuAYd281szzgCTN7wN2f6bfdre7+1XfxupHYt7qEMw6fzI1Pr+C8I2uZMrYo6pJERIbELlsEZtZiZs0D/LSY2S4vufVAa/gwL/zJ6XMwLz1+X5IJ48cPLou6FBGRIbPLIHD3EncvHeCnxN1L3+nFzSxpZouBDcBD7j5/gM3+zsxeMLPbzWzKTl7nQjOrM7O6hoboLu6qLktzwQencc/za3lhdVNkdYiIDKWsnvnj7j3ufijBlcizzezAfpvcC9S6+8HAQ8DcnbzONe4+091nVlZWZrPkd/Slo6Yxdkw+/3b/Ek1wLyKjwrCcAuruTcA84IR+yze5e0f48Frg8OGoZ3eUpPO45Ni9eeaNRuYt2/DOTxARGeGyFgRmVmlm5eH9QuB4YGm/bWoyHp4KLMlWPUPp07OnUjuuiH+/fyndPaNyojYRiZFstghqgHlm9gLwLMExgvvM7HIzOzXc5mvhqaXPA18DzstiPUMmP5Xg2ydM57UNrdyxaHXU5YiI7BbLtX7umTNnel1dXdRl4O6c/qunWLN5Gw9dehRlhaN6VG4RyXFmttDdZw60LhbDRGSDmfH9k/dn89ZO/n5uncYhEpGcpSDYDTOmVnDFWYfy7MpGvvq753S8QERykoJgN5188EQuP/UAHl6ynsvufFGnlIpIzhn0EBOyc+ceUUtDayf//ZfXGFdcwHc+Pj3qkkREBk1BMES+cdzebGrt4OrHXmd8cT4XfGha1CWJiAyKgmCImBmXn3Ygm7d28q9/XMLYMfmcftjkqMsSEXlHCoIhlEwYV5x1KE1bn+Vbt79AeVEex0yvirosEZFd0sHiIVaQSnLN52ayf00pF9+8iIUrG6MuSURklxQEWVBckOKG82dRU1bI+Tc8y7L6lqhLEhHZKQVBlowvLuDGL8wmnZfkc9fPZ/XmrVGXJCIyIAVBFk0ZW8SNX5zNts4ePnfdAja1drzzk0REhpmCIMumV5dy/XmzWNO0jbOueYa3NqllICIji4JgGMysHctvz59NQ0sHn/jlkzy7QgeQRWTkUBAMkyP2HMddFx9JWWEen/3NfO7U8NUiMkIoCIbRtMpi7rr4SA7fo4JLb3ueHz+4lN5ejU0kItFSEAyz8qJ85n5hNmfPmsJV817nK79bxLZODWEtItFREEQgP5Xg308/iO+dtB9/ermes655mvXN7VGXJSIxpSCIiJlxwYem8ZtzZ7J8QyunXfkkL63ZEnVZIhJDCoKIHbd/FbdfdCQJg09d/TQPvlwfdUkiEjMKghFg/4ml3P2VOexTVcxFNy3k6sde1wQ3IjJsFAQjxITSNLd+6QhOPKiGHz2wlHOum8+qRl18JiLZpyAYQdJ5Sa789Ax++MkDeX7VFj56xV/57ZNv6hRTEckqBcEIY2Z89v178OA3Pszs943lB/e+wlnXPM0bDa1RlyYio5SCYISaVF7Ib8+fxU8+dQjL6lv4+M8f59ePvU53T2/UpYnIKKMgGMHMjDMOn8zDlx7FUftU8u8PLOX0Xz3F0vrmqEsTkVFEQZADJpSm+fW5h3PlZ2awZvM2TvnFE/z84dfo7FbrQER2n4IgR5gZJx88kT9/48N8/MAarnj4VU698gkWr2qKujQRyXEKghwzrriA//70DH7zuZk0tnXyiaue5Bu3LmZt07aoSxORHJWKugB5b47fv4oPTBvL1Y+9zm8ef5P7X1zH339oGhcdvSfFBfpYRWTw1CLIYSXpPL71sek88s2jOOHAaq6ct5yjf/wotyx4ix5deyAig6QgGAUmVxTx87NncPdX5lA7rojv3PkiJ/334zz+WkPUpYlIDlAQjCKHTinnDxcdwS8/exhtnd2ce90Czr9hAcs3tERdmoiMYFkLAjNLm9kCM3vezF42s38ZYJsCM7vVzJab2Xwzq81WPXFhZpx4UA0PX3oU3z1xOnUrN/Oxnz3O9+5+UWMXiciALFujXJqZAWPcvdXM8oAngEvc/ZmMbS4GDnb3i8zsbOCT7n7Wrl535syZXldXl5WaR6PGtk5+/vCr3Dz/LXrdOeHAar74wWkcvkdF1KWJyDAys4XuPnPAdcMx3LGZFREEwZfdfX7G8geBH7j702aWAuqBSt9FUQqC92bdlm3MfWolv5u/kub2bmZMLeeCD07jYwdUkUqqh1BktIssCMwsCSwE9gKucvdv91v/EnCCu68OH78OvN/dN/bb7kLgQoCpU6cevnLlyqzVPNq1dXRzx6LVXP/Em6zYtJVJ5YWcP6eWM2dNoTSdF3V5IpIlI6FFUA7cBfyDu7+UsXxQQZBJLYKh0dPr/GXJeq594k0WvNlIcUGKs2ZN4bwja5kytijq8kRkiO0qCIblyiN3bzKzecAJwEsZq9YAU4DVYddQGbBpOGqKu2TC+OgB1Xz0gGpeXL2F6554g7lPreCGJ9/k2P2qOGvmFI7et1LdRiIxkLUgMLNKoCsMgULgeOA/+m12D/B54GngDOCRXR0fkOw4aHIZPzt7Bt/++HRufHolf6hbxUOvrGdCSQFnHD6ZM2dOoXb8mKjLFJEsyeZZQwcDc4EkwWmqt7n75WZ2OVDn7veYWRr4H2AG0Aic7e5v7Op11TWUfV09vTyydAO3PruKR5dtoNfhA9PGcvasqZxwYDXpvGTUJYrIuxT5MYKhpCAYXvVb2rl94Spuq1vNW41bKU2n+MSMSZw5cwoHTiqLujwRGSQFgey23l7nmTc2cWvdKh54qZ7O7l4OmFjKaYdO5OSDJzKxvDDqEkVkFxQEMqSatnbyv4vXcvvC1by4ZgsAs2vHcsqhEznxwGrGFRdEXKGI9KcgkKx5c2Mb9z6/lnueX8vyDa0kE8acvcZz6iET+dgBVZTo2gSREUFBIFnn7ixZ18K9L6zl3ufXsnrzNvJTCY7ZdwKnHDKRY6ZPoDBfB5lFoqIgkGHl7ix6q4l7n1/LfS+sY2NrBwWpBEfuOY5jpk/gI9MnMLlCF62JDCcFgUSmp9eZ/8YmHlqynkeWbmDlpmAE1H2rSjhmvwkcO30CM6ZWkExYxJWKjG4KAhkR3J03NrbxyJINPLJ0A8+uaKS71ykvyuPofSr5yPQJHLVPJeVF+VGXKjLqKAhkRNqyrYvHX2vgkaUbeHRZA41tnSQMDppczpw9xzFnr/EcvkeFLmATGQIKAhnxenqd51c38eiyBp5avpHnVjXR0+vkpxLM3KOCOXuNZ85e4zloUpm6kUTeAwWB5JzWjm4WvLmJJ5dv4snlG1laH0y3WZJO8YFp45iz5ziO2HM8e08oJqFgEHlHkY8+KvJuFRekOGZ6FcdMrwJgY2sHT72+iaeWb+SJ5Rt56JX1AJQX5TGrdiyza8cy+31jOWBiqUZMFXmXFASSE8YXF3DqIRM59ZCJALy1aSvz39zEgjcbeXZF4/ZgGJOf5LA9KrYHwyFTynWMQeQdqGtIRoX1ze0seLNxezD0dSXlJxMcMqWMw6ZWMGNqOYdNrWBCaTriakWGn44RSOw0be2kbsVmFqwIwuGVtc109vQCMKm8kBlTy5kxtYLDppaz/8RSClJqNcjopmMEEjvlRfkct38Vx+0fHGPo6O7h5bXNLFq5medWNbFo5Wbue2EdELQaDphUymFTKzhwUin7VpWy54QxCgeJDQWBxEJBKslhUys4bGrF9mX1W9p57q0dwXDTMyvp6A5aDcmE8b7xY9i3uoR9q0rYt7qE6dUlTKko0llKMuqoa0gk1NXTy5sb21ha38Kr9S3B7foW3mrcun2bwrwk+1QVs09VCftUlbBXeH9iWRozBYSMXOoaEhmEvGRi+xc8h+xY3tbRzavrg1DoC4d5yzbwh4Wrt28zJj/JXlUl7DOhmL2ritm7qoS9JxQzqbxQASEjnoJA5B2MKUgxY2oFMzK6lQAa2zp5bX0Lr21o3X47b1nD3wTEPtUl7FdTyv41pexXU8r06hLGFOhXT0YOdQ2JDLHNbZ0sb2jl1fUtvLa+lSXrmlmyrpnm9m4AzKB23Bj2qylhv+pS9p8YBESNupcki9Q1JDKMKsbkM2vMWGbVjt2+zN1Z07SNJetaWLKumVfWNvPy2mbuf7F++zYl6RSTK4qYVF7IpPI0E8sLmVRRyMTyQiaXFzK+uEAHqiUrFAQiw8DMmFxRxOSKIo4PT2kFaGnvYll9EA6vrm9lbdM2Vm8OrppuCVsQffKTCWrK00wsK2RyRRASwWsGj6tL0xpeQ94TBYFIhErSecysHcvMjNZDn+b2LtY2bWPN5m3BbVM7a5q2sWbzVv76WgMbWjrI7NlNJoyasjSTyt8eEJMripgyVkEhO6cgEBmhStN5lFbnMb26dMD1Hd09rGtqZ/XmoBXRd7umaRtPvb6R+ub2AYNiyvaQCAIiMyh0jCKeFAQiOaoglaR2/Bhqx48ZcH1nd2/Y1bQjKFaFt4+9GrQoMp0+YxI/+dQhOg4RQwoCkVEqP5XYZVC0d/WwJgyKR5dt4IYnV1BTnuZbH5s+zJVK1BQEIjGVzkuyZ2Uxe1YW8+G9x9Pe1cNV815n6tgizpo1NeryZBgpCEQEM+Py0w5kTVM7373rJWrKCvnwPpVRlyXDRKcQiAgQDLFx1WdmsPeEYi6+eRFL65ujLkmGiYJARLYrSedxw/mzGFOQ5As3PMv65vaoS5JhoCAQkbepKSvk+vNmsWVbF1/47bO0dXS/85MkpykIRORvHDCxjCs/cxhL1jXzD79/ju5wdjcZnbIWBGY2xczmmdkrZvaymV0ywDZHm9kWM1sc/nw/W/WIyLvzkekTuPy0A3lk6QYuv+8Vcm2AShm8bJ411A18090XmVkJsNDMHnL3V/pt97i7n5zFOkTkPTrnA3vwVuNWrvnrG0wdW8QFH5oWdUmSBVkLAndfB6wL77eY2RJgEtA/CERkBPvOCdNZ1biVH96/hMkVhZxwYE3UJckQG5ZjBGZWC8wA5g+w+ggze97MHjCzA3by/AvNrM7M6hoaGrJYqYj0l0gYV5x1KIdOKeeSWxbz3Fuboy5JhljWJ6Yxs2LgMeCH7n5nv3WlQK+7t5rZicDP3X3vXb2eJqYRicam1g4++cunqN/STllRHvnJBAWpBPmpHbf5qQT5yb5lScYUJClN51GSTlFaGNyWFORtv993W5yf0hhHWRbZxDRmlgfcAdzcPwQA3L054/79ZvZLMxvv7huzWZeIvHvjigu46Yvv58anV9DW2UNHdw+d3b3BT09w29HVS/O27u3LWju6aWnvor3rnc86yksaeckdYZIXBk3fsrykkZ9KkM5LUpSf3H5blJ/afr8wL0lh321ekmTSyEskSCaMvKSRTBipRIJU0kgljFQyQSphpPOSFBekSOclYjkCa9aCwIJ/zeuAJe7+051sUw2sd3c3s9kEXVWbslWTiOyeqeOK+N7J+7/r53V299LS3kVzezfN27poae+mub0rWLatm9aObjp7eukKA6Srp5eOMGS6evpunc7uXhrbOlm9uYdtnT1s6+pha2f3oIJmMBIWzFFdXJBiTEGKMfnJ4DZcVpSfpCCVpCAvCKmCVHJ7i2hH6yhY3xdmfQE34P1UgryMYIoqhLLZIpgDnAu8aGaLw2XfBaYCuPvVwBnAl82sG9gGnO06R01k1MlPJRhXXMC44oKsvH5vr9PeHYTD1s4e2ruCkOjudXp6na6eXnp6ne4eD5cFwdK3rr2rh9aOHto6glBq6+imrbObtnBZY9tW2jq72doRtII6wsAaakErxXaEQzJBXl/LJWl8ZvbUrJy5lc2zhp4Adhlv7n4lcGW2ahCReEgkjKL8FEX5KcYN03v29jqdYculo7uHjq6M+91B66arx+nq3XG/u3dH66YrbPl09TjdPb109Qa33WE4dYfbZ66vLMlOkGr0URGR9yCRMNKJ4FgF5EVdzm7REBMiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5rI++uhQM7MGYGW/xeOB0TRQ3WjbHxh9+zTa9gdG3z6Ntv2B3dunPdy9cqAVORcEAzGzup0Nr5qLRtv+wOjbp9G2PzD69mm07Q9kb5/UNSQiEnMKAhGRmBstQXBN1AUMsdG2PzD69mm07Q+Mvn0abfsDWdqnUXGMQERE3rvR0iIQEZH3SEEgIhJzOR0EZnaCmS0zs+Vm9sti2LIAAATuSURBVJ2o6xkKZrbCzF40s8VmVhd1Pe+FmV1vZhvM7KWMZWPN7CEzey28rYiyxndjJ/vzAzNbE35Oi83sxChrfDfMbIqZzTOzV8zsZTO7JFyey5/RzvYpJz8nM0ub2QIzez7cn38Jl7/PzOaH33m3mln+kLxfrh4jMLMk8CpwPLAaeBb4tLu/Emlhu8nMVgAz3T1nL4Qxsw8DrcCN7n5guOw/gUZ3/1EY2hXu/u0o6xysnezPD4BWd/9JlLW9F2ZWA9S4+yIzKwEWAp8AziN3P6Od7dOZ5ODnZMEs9mPcvdXM8oAngEuAS4E73f0WM7saeN7df7W775fLLYLZwHJ3f8PdO4FbgNMirkkAd/8r0Nhv8WnA3PD+XIJf0pywk/3JWe6+zt0XhfdbgCXAJHL7M9rZPuUkD7SGD/PCHweOAW4Plw/ZZ5TLQTAJWJXxeDU5/MFncODPZrbQzC6MupghVOXu68L79UBVlMUMka+a2Qth11HOdKNkMrNaYAYwn1HyGfXbJ8jRz8nMkma2GNgAPAS8DjS5e3e4yZB95+VyEIxWH3T3w4CPA18JuyVGFQ/6I3OzT3KHXwF7AocC64D/iracd8/MioE7gK+7e3Pmulz9jAbYp5z9nNy9x90PBSYT9IBMz9Z75XIQrAGmZDyeHC7Lae6+JrzdANxF8B9gNFgf9uP29eduiLie3eLu68Nf1F7gN+TY5xT2O98B3Ozud4aLc/ozGmifcv1zAnD3JmAecARQbmapcNWQfeflchA8C+wdHkXPB84G7om4pt1iZmPCA12Y2Rjgo8BLu35WzrgH+Hx4//PA/0ZYy27r+8IMfZIc+pzCA5HXAUvc/acZq3L2M9rZPuXq52RmlWZWHt4vJDgpZglBIJwRbjZkn1HOnjUEEJ4K9jMgCVzv7j+MuKTdYmbTCFoBACngd7m4T2b2e+BogiFz1wP/H7gbuA2YSjCM+JnunhMHYHeyP0cTdDc4sAL4Ukb/+ohmZh8EHgdeBHrDxd8l6FPP1c9oZ/v0aXLwczKzgwkOBicJ/mC/zd0vD78jbgHGAs8B57h7x26/Xy4HgYiI7L5c7hoSEZEhoCAQEYk5BYGISMwpCEREYk5BICIScwoCkWFkZkeb2X1R1yGSSUEgIhJzCgKRAZjZOeF48IvN7NfhAGCtZnZFOD78X8ysMtz2UDN7JhzY7K6+gc3MbC8zezgcU36Rme0Zvnyxmd1uZkvN7ObwqliRyCgIRPoxs/2As4A54aBfPcBngTFAnbsfADxGcIUxwI3At939YIIrW/uW3wxc5e6HAEcSDHoGwciYXwf2B6YBc7K+UyK7kHrnTURi51jgcODZ8I/1QoIB2HqBW8NtbgLuNLMyoNzdHwuXzwX+EI4ZNcnd7wJw93aA8PUWuPvq8PFioJZg4hGRSCgIRP6WAXPd/bK3LTT7537bvdfxWTLHhulBv4cSMXUNifytvwBnmNkE2D6X7x4Evy99Iz9+BnjC3bcAm83sQ+Hyc4HHwlmyVpvZJ8LXKDCzomHdC5FB0l8iIv24+ytm9j2CmeISQBfwFaANmB2u20BwHAGC4YCvDr/o3wDOD5efC/zazC4PX+NTw7gbIoOm0UdFBsnMWt29OOo6RIaauoZERGJOLQIRkZhTi0BEJOYUBCIiMacgEBGJOQWBiEjMKQhERGLu/wB7ssnh/L5SlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxddZ3/8dcn682+L13SjdIWsQtSqmyyuQ0qOCOCOiioM1VHRxx1ZJyfP8cfj9kYl3EUHyAjKriBImiHwaXsi7KkdGFpoaW2TdNmadPsW5N8fn+ck5CGtAaam5Ob834+HveRm3POvedzuOW+c77f7/kec3dERCS+0qIuQEREoqUgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQSKyY2Q/M7J8nuO0uM3tTsmsSiZqCQEQk5hQEIinIzDKirkFmDgWBTDthk8zfm9kWM+sys5vMrMrMfm1mHWZ2j5mVjNr+IjN71sxazewBMztp1LpTzOyp8HW3AYkx+3qHmW0KX/t7M1sxwRrfbmYbzazdzOrM7Mtj1p8Vvl9ruP7KcHmOmX3NzHabWZuZPRIuO9fM9o7z3+FN4fMvm9ntZvYjM2sHrjSzNWb2h3Af+83sOjPLGvX6k81svZm1mFmjmf2jmVWbWbeZlY3a7nVm1mxmmRM5dpl5FAQyXb0beDOwBHgn8GvgH4EKgn+3nwIwsyXAT4FPh+vuBv7HzLLCL8VfAj8ESoGfh+9L+NpTgO8BHwXKgO8A68wsewL1dQEfBIqBtwMfN7N3he87P6z3W2FNq4BN4eu+CpwKnBHW9HlgaIL/TS4Gbg/3+WNgEPg7oBw4HbgA+JuwhgLgHuA3wGxgMXCvuzcADwCXjnrfDwC3uvvhCdYhM4yCQKarb7l7o7vXAw8Dj7v7RnfvBe4ETgm3uwz4X3dfH36RfRXIIfiifQOQCXzD3Q+7++3Ak6P2sRb4jrs/7u6D7n4z0Be+7pjc/QF3f9rdh9x9C0EYnROufj9wj7v/NNzvQXffZGZpwIeBq9y9Ptzn7929b4L/Tf7g7r8M99nj7hvc/TF3H3D3XQRBNlzDO4AGd/+au/e6e4e7Px6uuxm4HMDM0oH3EYSlxJSCQKarxlHPe8b5PT98PhvYPbzC3YeAOmBOuK7ej5xZcfeo5/OBz4ZNK61m1grUhK87JjN7vZndHzaptAEfI/jLnPA9XhznZeUETVPjrZuIujE1LDGzu8ysIWwu+tcJ1ADwK+A1ZraQ4Kyrzd2feJU1yQygIJBUt4/gCx0AMzOCL8F6YD8wJ1w2bN6o53XAv7h78ahHrrv/dAL7/QmwDqhx9yLgBmB4P3XACeO85gDQe5R1XUDuqONIJ2hWGm3sVMHXA9uAE929kKDpbHQNi8YrPDyr+hnBWcEH0NlA7CkIJNX9DHi7mV0QdnZ+lqB55/fAH4AB4FNmlmlmfwGsGfXa/wY+Fv51b2aWF3YCF0xgvwVAi7v3mtkaguagYT8G3mRml5pZhpmVmdmq8Gzle8DXzWy2maWb2elhn8QLQCLcfybwReBP9VUUAO1Ap5ktAz4+at1dwCwz+7SZZZtZgZm9ftT6W4ArgYtQEMSegkBSmrs/T/CX7bcI/uJ+J/BOd+93937gLwi+8FoI+hPuGPXaWuCvgeuAQ8COcNuJ+BvgGjPrAL5EEEjD77sHuJAglFoIOopXhqs/BzxN0FfRAlwLpLl7W/ie3yU4m+kCjhhFNI7PEQRQB0Go3Taqhg6CZp93Ag3AduC8UesfJeikfsrdRzeXSQyZbkwjEk9mdh/wE3f/btS1SLQUBCIxZGanAesJ+jg6oq5HoqWmIZGYMbObCa4x+LRCQEBnBCIisaczAhGRmEu5iavKy8t9wYIFUZchIpJSNmzYcMDdx16bAqRgECxYsIDa2tqoyxARSSlmdtRhwmoaEhGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmYhME2xra+cpvt9HWrduyioiMFpsg2H2wm2/f/yJ1h7qjLkVEZFqJTRBUFSYAaGzvjbgSEZHpJUZBENz1r7G9L+JKRESml9gEQXl+NmbQoDMCEZEjxCYIMtPTKM/PpklBICJyhNgEAQTNQ+ojEBE5UryCoCChPgIRkTFiFQSVhQmdEYiIjBGrIKguTHCwq5/+gaGoSxERmTZiFQTDQ0ibO9U8JCIyLGZBEFxU1tCm5iERkWGxDAINIRUReUnMgmD46mIFgYjIsFgFQUluFpnpRmOH+ghERIbFKgjS0ozKggSN6iMQERkRqyCA8OriDgWBiMiwGAaBri4WERktpkGgMwIRkWGxC4LKwmw6egfo7h+IuhQRkWkhqUFgZrvM7Gkz22RmteOsP9fM2sL1m8zsS8msB4JpJkA3qBERGZYxBfs4z90PHGP9w+7+jimoAzjylpULy/OmarciItNW7JqGdFGZiMiRkh0EDvzOzDaY2dqjbHO6mW02s1+b2cnjbWBma82s1sxqm5ubj6ugSt3EXkTkCMluGjrL3evNrBJYb2bb3P2hUeufAua7e6eZXQj8Ejhx7Ju4+43AjQCrV6/24ymoIDuD3Kx09RGIiISSekbg7vXhzybgTmDNmPXt7t4ZPr8byDSz8mTWZGYaQioiMkrSgsDM8sysYPg58BbgmTHbVJuZhc/XhPUcTFZNwyoLsmnSGYGICJDcpqEq4M7wez4D+Im7/8bMPgbg7jcAlwAfN7MBoAd4r7sfV9PPhAorTLCprjXZuxERSQlJCwJ33wmsHGf5DaOeXwdcl6wajqa6KEHjs724O2FQiYjEVuyGj0LQNNQ3MER7j64uFhGJZRCMXFSmWUhFROIdBLp3sYhITIOgWheViYiMiGUQVIbTTDTplpUiIvEMgkRmOkU5mTojEBEhpkEAweRz6iMQEYl1ECRoVNOQiEi8g6BJTUMiInEOgmyaOvoYGkr6jBYiItNabIOgujDB4JBzoEvNQyISb7ENguEb1GgWUhGJu9gGQZUuKhMRAWIdBMFFZQ0KAhGJudgGQUV+NmbolpUiEnuxDYKM9DTK87M1hFREYi+2QQBB85D6CEQk7uIdBAUJGtQ0JCIxF+8gKNLVxSIi8Q6CggQHu/rpHxiKuhQRkcjEOwjCIaTNnWoeEpH4inkQ6JaVIiIKAlA/gYjEWlKDwMx2mdnTZrbJzGrHWW9m9k0z22FmW8zsdcmsZ6zhpiENIRWROMuYgn2c5+4HjrLuz4ATw8frgevDn1OiJDeLzHTTDWpEJNaibhq6GLjFA48BxWY2a6p2npZmVBYkaFQfgYjEWLKDwIHfmdkGM1s7zvo5QN2o3/eGy6ZMVWE2jR0KAhGJr2Q3DZ3l7vVmVgmsN7Nt7v7QK32TMETWAsybN29SC6wqTLC9qXNS31NEJJUk9YzA3evDn03AncCaMZvUAzWjfp8bLhv7Pje6+2p3X11RUTGpNVYVJtRZLCKxlrQgMLM8MysYfg68BXhmzGbrgA+Go4feALS5+/5k1TSeysJsOnoH6O4fmMrdiohMG8lsGqoC7jSz4f38xN1/Y2YfA3D3G4C7gQuBHUA38KEk1jOu6pE7lfWxsHwqBlGJiEwvSfvmc/edwMpxlt8w6rkDn0hWDRMx+paVC8vzoixFRCQSUQ8fjZwuKhORuIt9EFTqJvYiEnOxD4KC7Axys9J172IRia3YB4GZaQipiMRa7IMAoLIgmyadEYhITCkICEYONeiMQERiSkEAVBcFTUPBaFYRkXhREBA0DfUNDNHeo6uLRSR+FASMuqhMs5CKSAwpCAiahkD3LhaReFIQAFUFuqhMROJLQUAwAylAk25ZKSIxpCAAEpnpFOVk6oxARGJJQRCqLkyoj0BEYklBEKoszKZRTUMiEkMKglBVYYImNQ2JSAwpCEJVhdk0dfQxOKSri0UkXhQEoerCBINDzsEuNQ+JSLwoCELDN6jRLKQiEjcKglCV7lQmIjGlIAgN37tY01GLSNwoCEIV+dmYoVtWikjsKAhCGelplOdnawipiMSOgmCUqsJs9RGISOwkPQjMLN3MNprZXeOsu9LMms1sU/j4q2TXcyxVBQka1DQkIjGTMQX7uArYChQeZf1t7v7JKajjT6oqSrCprjXqMkREplRSzwjMbC7wduC7ydzPZKkqSHCwq5/+gaGoSxERmTLJbhr6BvB54FjfrO82sy1mdruZ1Yy3gZmtNbNaM6ttbm5OSqHw0hDS5k41D4lIfCQtCMzsHUCTu284xmb/Ayxw9xXAeuDm8TZy9xvdfbW7r66oqEhCtYHhi8o0HbWIxEkyzwjOBC4ys13ArcD5Zvaj0Ru4+0F3H/7z+7vAqUms50+qGplmQkEgIvGRtCBw9y+4+1x3XwC8F7jP3S8fvY2ZzRr160UEncqRGW4a0hBSEYmTqRg1dAQzuwaodfd1wKfM7CJgAGgBrpzqekYryc0iM910gxoRiZUpCQJ3fwB4IHz+pVHLvwB8YSpqmIi0NKOyIEGj+ghEJEYm1DRkZleZWaEFbjKzp8zsLckuLgpVhdk0digIRCQ+JtpH8GF3bwfeApQAHwD+PWlVRaiqMKGJ50QkViYaBBb+vBD4obs/O2rZjBIEgc4IRCQ+JhoEG8zsdwRB8FszK+DYF4mlrKrCBB29A3T3D0RdiojIlJhoZ/FHgFXATnfvNrNS4EPJKys6Lw0h7WNh+ZQPqhIRmXITPSM4HXje3VvN7HLgi0Bb8sqKjm5ZKSJxM9EguB7oNrOVwGeBF4FbklZVhHRRmYjEzUSDYMDdHbgYuM7dvw0UJK+s6OiMQETiZqKN4B1m9gWCYaNnm1kakJm8sqKTn51Bbla6hpCKSGxM9IzgMqCP4HqCBmAu8JWkVRUhM2NWUYJn983ILhARkZeZUBCEX/4/BorC6aV73X1G9hEAXLq6hsd2tvDYzoNRlyIiknQTnWLiUuAJ4D3ApcDjZnZJMguL0hVnLKCqMJv/+M02gq4REZGZa6JNQ/8HOM3dr3D3DwJrgP+bvLKilchM56oLlvDUnlbu3doUdTkiIkk10SBIc/fR34gHX8FrU9J7Vs9lQVkuX/nt8wwO6axARGauiX6Z/8bMfmtmV5rZlcD/Ancnr6zoZaan8dm3LOX5xg7Wba6PuhwRkaSZaGfx3wM3AivCx43ufnUyC5sO3r58Fq+ZVcjX179A/8CMnFpJRGTizTvu/gt3/0z4uDOZRU0XaWnG379tKXUtPdz65J6oyxERSYpjBoGZdZhZ+ziPDjNrn6oio3TukgrWLCzlm/fu0IykIjIjHTMI3L3A3QvHeRS4e+FUFRklM+Pqty3lQGcf3390V9TliIhMuhk98meynDq/lDedVMkND75Ia3d/1OWIiEwqBcEEfe6tS+nsG+CGB3dGXYqIyKRSEEzQsupCLl45m+8/+kfNTCoiM4qC4BX4zJuXMjjkfPPe7VGXIiIyaRQEr8C8slzet2Yetz1Zx64DXVGXIyIyKZIeBGaWbmYbzeyucdZlm9ltZrbDzB43swXJrud4/e35i8lIN76+/oWoSxERmRRTcUZwFbD1KOs+Ahxy98XAfwLXTkE9x6WyMMGHz1zIus37eG5fLC6lEJEZLqlBYGZzgbcD3z3KJhcDN4fPbwcuMDNLZk2T4aNvPIHCRAZf/d3zUZciInLckn1G8A3g88DRJuqZA9QBuPsA0AaUjd3IzNaaWa2Z1TY3Nyer1gkrys3kY+eewH3bmnhyV0vU5YiIHJekBUF4J7Mmd99wvO/l7je6+2p3X11RUTEJ1R2/D52xkMqCbK79tW5eIyKpLZlnBGcCF5nZLuBW4Hwz+9GYbeqBGgAzywCKCO51MO3lZKXzqQtOpHb3Ia67b0fU5YiIvGpJCwJ3/4K7z3X3BcB7gfvc/fIxm60DrgifXxJukzJ/Xr9/zTz+4pQ5fG39C/z48d1RlyMi8qpkTPUOzewaoNbd1wE3AT80sx1AC0FgpIy0NOPaS1bQ2nOYL/7yGUpys7hw+ayoyxIReUUshf4AB2D16tVeW1sbdRlH6Okf5PKbHufpvW384EOnccbi8qhLEhE5gpltcPfV463TlcWTICcrne9dcRoLy/P461tqeXpvW9QliYhMmIJgkhTlZnLzh9dQnJvFld9/gp3NnVGXJCIyIQqCSVRdlOCHH1kDwAduekKzlIpISlAQTLJFFfn84ENraO3u54M3PUFb9+GoSxIROSYFQRIsn1vEf39wNX880MVHbn6Snv7BqEsSETkqBUGSnLG4nP967yo27DnEJ37yFIcHjzbLhohItBQESfRny2fxz+96Lfdta+Lq27cwNJRaQ3VFJB6m/IKyuPnL18+npbOfr61/gYx045qLX0siMz3qskRERigIpsAnz1/M4cEhvnnfDjbXtfGt95/CkqqCqMsSEQHUNDQlzIzPvGUpN394DQe7+rjouke49Yk9mrVURKYFBcEUOmdJBXdfdTar55fyD3c8zSd/upH2Xg0vFZFoKQimWGVBgls+vIar37aM3zzTwIX/9TAb9xyKuiwRiTEFQQTS0oyPn3sCP//Y6QC854Y/cP0DL2pUkYhEQkEQodfNK+F/P3U2bz25mmt/s40rvv8ETR2alkJEppaCIGJFOZlc9/5T+Nc/X84Tf2zhwv96mIdeiP6+zCISHwqCacDMeP/r5/E/f3sWpXlZfPB7T3DVrRvZ19oTdWkiEgMKgmlkSVUBv/rEWXzyvMX8+pkGzv/aA3zjnhc0V5GIJJWCYJrJyUrnc29dyr2fOYcLllXxjXu2c8HXHuBXm+p13YGIJIWCYJqqKc3l23/5Om5b+wZK8rK46tZNvPv637O5rjXq0kRkhlEQTHOvX1TGuk+exbXvXs6elm4u/vajfOZnm3TTGxGZNAqCFJCeZlx22jzu/9y5fPScRdy1eT/nffUBrrtvO72H1X8gIsfHUq3defXq1V5bWxt1GZHafbCLf717K799tpHy/GyuPGM+l79hPsW5WVGXJiLTlJltcPfV465TEKSux3Ye5PoHXuTBF5rJyUznstNq+MhZC6kpzY26NBGZZo4VBJqGOoW9YVEZb1hUxraGdm58aCc/emw3t/xhFxcun8VH33gCy+cWRV2iiKSApJ0RmFkCeAjIJgic2939n8ZscyXwFaA+XHSdu3/3WO+rM4Kj29/Www8e3cVPHt9DR98Apy8qY+05izh3SQVmFnV5IhKhSJqGLPjmyXP3TjPLBB4BrnL3x0ZtcyWw2t0/OdH3VRD8ae29h7n1iT1875FdNLT3sqQqn786exHvXDGbnCzdHU0kjo4VBEkbNeSBzvDXzPCRWh0SKaowkcnaN57AQ58/j69fupI0Mz5/+xbW/Ms9fOGOLWzYfUgXp4nIiKR2FptZOrABWAx8292vHrP+SuDfgGbgBeDv3L1unPdZC6wFmDdv3qm7d+9OWs0zkbvz+B9b+HntXu5+ej89hwc5oSKPS06t4d2vm0NlYSLqEkUkySIfNWRmxcCdwN+6+zOjlpcBne7eZ2YfBS5z9/OP9V5qGjo+nX0D3L1lPz/fUMeTuw6Rnmacs6SC95w6lwtOqiIrQ5eWiMxEkQdBWMSXgG53/+pR1qcDLe5+zKEuCoLJs7O5k9s37OWOp+ppaO+lJDeTi1fN4ZJT53Ly7EJ1MIvMIFF1FlcAh9291cxygN8B17r7XaO2meXu+8Pnfw5c7e5vONb7Kggm3+CQ8/D2Zn6+YS/rn22kf3CIReV5XLRqNhetnM2iivyoSxSR4xRVEKwAbgbSCTqlf+bu15jZNUCtu68zs38DLgIGgBbg4+6+7VjvqyBIrtbufn79TAPrNu3jsT8exB2Wzyni4lWzeceK2VQXqT9BJBVNi6ahyaIgmDoNbb3ctWUf6zbvY8veNszg9QtLuWjlHC5cXq0pLURSiIJAjtvO5k7Wbd7Huk372Hmgi8x04+wTK3jryVWcv6yKioLsqEsUkWNQEMikcXee3dfOrzbVc/fTDdS39mAGq2qKedNJVbz5NVWcWJmvjmaRaUZBIEnh7mzd38E9Wxu5Z2sjW/a2AVBTmhOEwklVnLawlMx0DUkViZqCQKZEY3sv925t4p6tjTyy4wD9A0MUJDI4b2kl5y2r4MwTynXxmkhEFAQy5br7B3h4+wHuea6R+7Y1cbCrH4ClVQWcdWI5Zy0uZ83CUvKyNQGuyFRQEEikhoac5/a38/D2Azy64wBP7Gqhf2CIzHTjlHklnL24nDNPLGfFnCIy1IwkkhQKAplWeg8PUrvrEA/vaObRHQd4pr4dgIJEBmecUMa5Sys5d2kFs4pyIq5UZObQjWlkWklkpgfNQyeWA9DS1c/vXzzAI9sP8NALzfz22UYATppVyHlLKzhvWSWn1BTrbEEkSXRGINOKu/NCYyf3P9/E/duaqN19iMEhpzCRwRuXVHD+skrOWVJBWb6uWxB5JdQ0JCmrrecwj2w/wP3PN/HA880c6OzDDFbMLeasxWWctqCU180voTCRGXWpItOagkBmhKGh4GK2+59v4v7nm9iyt43BISfNYFl1IactKOG0haWctqCUKg1TFTmCgkBmpK6+ATbVtfLkrhae3NXCU7tb6Tk8CAQXtZ22oDR8lLCoPJ+0NF3tLPGlzmKZkfKyMzhzcTlnLg46nQ8PDvHcvvaRYHjw+WbueKoegILsDJbPLWJlTTErw5/VhQlNhSGCzghkBnN3/nigi9rdh9iyt5XNdW1s3d/OwFDwb76yIJsVc4tZVRMEw4o5xRTlqq9BZiadEUgsmRmLKvJZVJHPpatrgOAahq3729lc18rmvW1s3tvKPVsbR16zoCyXFXOLWTG3iBVzizl5dqGufpYZT//CJVYSmemcMq+EU+aVjCxr6znMM/VtbKprZcveVmp3tbBu8z4A0gwWV+azfM5wOBRx0qxCEpnpUR2CyKRTEEjsFeVkHtHXANDc0cfT9UFz0tP1bTz4QhO/eGovABlpxtLqAlbVFLOqpphT5pWwqDxPndGSstRHIDIB7s7+tl627G1lS9iktLmujc6+ASCYHmNVTTGn1BSzal4xq2pKKM3THdxk+lAfgchxMjNmF+cwuziHt712FhBc1/Bicycb97Sysa6VjXsOcd39Owj7oplfljsSDqfMK+GkWYVkZWiaDJl+dEYgMom6+gZ4ur6NjXta2VR3iI17Wmnq6AMgKyON5XOKwuakIBxmF2kIq0wNXVAmEpHhJqWNe4Izhk11rWypb6N/YAgIhrAOh8KqmmKWzynSKCVJCjUNiURkdJPS21cETUr9A0Nsa2gfCYeNda0jM66mGZxYWcCK8KK3VTXFLK0u0O0+Jal0RiAyDRzs7BvpgA5+tnKo+zAQNCmdPLuQlXOLWVlTxMq5xSwo0ygleWXUNCSSYtydvYd6Rq5tGB7GOjyXUk5mOosr8zmxKp8TKwtYEv6cW5KjgJBxRdI0ZGYJ4CEgO9zP7e7+T2O2yQZuAU4FDgKXufuuZNUkkirMjJrSXGpKc3nnytkADAwOsaO5k811rWxr6GBHUyeP7jgwMp8SQCIzjcWV+SypLGBxVT6LK/KZU5LDnOIcinIy1TEt40pmH0EfcL67d5pZJvCImf3a3R8btc1HgEPuvtjM3gtcC1yWxJpEUlZGehrLqgtZVl14xPK27sPsaO7ghcZOtjd2sr2pg9+/eJA7NtYfsV1uVvpIf8Wc4gSzi4Lns4oTzCkOwkJ3gYunpAWBB21OneGvmeFjbDvUxcCXw+e3A9eZmXmqtVeJRKgoN5NT55dy6vzSI5a39Rzmjwe62Nfaw77WHupbe9jf2su+th6e29fGgc7+I7bPykhjcUU+y6oLWDargKXVhSyrLqCyIFtnEjNcUkcNmVk6sAFYDHzb3R8fs8kcoA7A3QfMrA0oAw6MeZ+1wFqAefPmJbNkkRmjKCdzZBqM8fQeHmR/W28QEod62NHcydb97Tyy48ARZxMluZksrS4Iz0YKOLGqgAVluZTmZSkgZoikBoG7DwKrzKwYuNPMXuvuz7yK97kRuBGCzuJJLlMklhKZ6Swsz2Nhed7L1h3q6mdbQwfbGtp5vqGDbQ0d3PZk3UhnNQT3eJhXlsv8slzmleaxoCw3/D2PWYUJdVqnkCm5jsDdW83sfuBtwOggqAdqgL1mlgEUEXQai0iESvKyOP2EMk4/oWxk2dCQU3eom+2Nnexu6Wb3wS52H+xm6/4O1j/XyOHBl/5Gy0pPo6Y0h7kluS/1SYz0T+RQVZjQdBvTSDJHDVUAh8MQyAHeTNAZPNo64ArgD8AlwH3qHxCZntLSjPllecwve/kZxOCQs6+1h90Hu9nd0sWeg93sPthNfWsPz9S3cbDryP4Is+Cq6tHhMKsowayiHGYXBz/L8rJ0VjFFknlGMAu4OewnSAN+5u53mdk1QK27rwNuAn5oZjuAFuC9SaxHRJIkPe2l4a5nUf6y9T39g+xv62Ffa+9Ix/Xwz2fr21j/XOPItBvDstLTqC5KMKsoOJuYVZRgVnEO1YUJqgsTVBVmU5afTbrC4rjpgjIRiZy7c7Crf2RU0/7WnqAju62XhjBAGtt7R24zOiw9zajIz6aqMJvKMByqCxNUhmExfLaRk6UbCWmuIRGZ1syM8vxsyvOzWT63aNxtBoecA519NLQFodDY0UdTe2/we0cfdS3d1O5qGZmaY7TSvCzmFAfNTnOKc5ldnGBuSc5I01RZzEdAKQhEJCWkpxlVhQmqChPH3K738CDNHX0vDY0dfhzqYWdzFw9vP0B3/+ARr8nKSAuanMKmqCOeFwXNURUFM7cZSkEgIjNKIjN9pL9iPO5Oa/fhIwKisb2X/W3B2cVTew7R2NZH/+CRfRbpaUZlQfZIQMwqygmD4qXnlQXZKXl1toJARGLFzCjJy6IkL4vXzhm/GcrdaenqZ3/YDDUcEvvbemlo72FbQwf3b2s+4roKCKYRrywIwqE8P5vSvExK8rIozc2iJDfYZ2leJiW5WZTmZVGYyJwWI6MUBCIiY5gZZfnBqKRjhUV7zwD724OO7f2tQcf2/jAwhofOtnT3v2xE1LA0C/ovhsOjqjCbquFRUUUJqsLlJbnJnTBQQSAi8iqYGTymHCAAAAYuSURBVEW5mRTlZr5sIsDR3J3u/kEOdfdzqOswLd39HOrqp6Wrn9bufpo7+4NO7/ZetuxtfdkcUBD0YVQVZnPF6Qv4q7MXTfqxKAhERJLIzMjLziAvO4O5JX96+/6BIZrD0VHDAdHQ3ktjWy8VBdlJqVFBICIyjWRlpI1MCz5VUq97W0REJpWCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYS7kb05hZM7B7zOJy4EAE5STLTDsemHnHNNOOB2beMc2044HjO6b57l4x3oqUC4LxmFnt0e68k4pm2vHAzDummXY8MPOOaaYdDyTvmNQ0JCIScwoCEZGYmylBcGPUBUyymXY8MPOOaaYdD8y8Y5ppxwNJOqYZ0UcgIiKv3kw5IxARkVdJQSAiEnMpHQRm9jYze97MdpjZP0Rdz2Qws11m9rSZbTKz2qjreTXM7Htm1mRmz4xaVmpm681se/hzAvdqmh6OcjxfNrP68HPaZGYXRlnjK2FmNWZ2v5k9Z2bPmtlV4fJU/oyOdkwp+TmZWcLMnjCzzeHx/L9w+UIzezz8zrvNzLImZX+p2kdgZunAC8Cbgb3Ak8D73P25SAs7Tma2C1jt7il7IYyZvRHoBG5x99eGy/4DaHH3fw9Du8Tdr46yzok6yvF8Geh0969GWdurYWazgFnu/pSZFQAbgHcBV5K6n9HRjulSUvBzsuBO9Xnu3mlmmcAjwFXAZ4A73P1WM7sB2Ozu1x/v/lL5jGANsMPdd7p7P3ArcHHENQng7g8BLWMWXwzcHD6/meB/0pRwlONJWe6+392fCp93AFuBOaT2Z3S0Y0pJHugMf80MHw6cD9weLp+0zyiVg2AOUDfq972k8Ac/igO/M7MNZrY26mImUZW77w+fNwBVURYzST5pZlvCpqOUaUYZzcwWAKcAjzNDPqMxxwQp+jmZWbqZbQKagPXAi0Cruw+Em0zad14qB8FMdZa7vw74M+ATYbPEjOJBe2Rqtkm+5HrgBGAVsB/4WrTlvHJmlg/8Avi0u7ePXpeqn9E4x5Syn5O7D7r7KmAuQQvIsmTtK5WDoB6oGfX73HBZSnP3+vBnE3AnwT+AmaAxbMcdbs9tirie4+LujeH/qEPAf5Nin1PY7vwL4Mfufke4OKU/o/GOKdU/JwB3bwXuB04His0sI1w1ad95qRwETwInhr3oWcB7gXUR13RczCwv7OjCzPKAtwDPHPtVKWMdcEX4/ArgVxHWctyGvzBDf04KfU5hR+RNwFZ3//qoVSn7GR3tmFL1czKzCjMrDp/nEAyK2UoQCJeEm03aZ5Syo4YAwqFg3wDSge+5+79EXNJxMbNFBGcBABnAT1LxmMzsp8C5BFPmNgL/BPwS+Bkwj2Aa8UvdPSU6YI9yPOcSNDc4sAv46Kj29WnNzM4CHgaeBobCxf9I0Kaeqp/R0Y7pfaTg52RmKwg6g9MJ/mD/mbtfE35H3AqUAhuBy92977j3l8pBICIixy+Vm4ZERGQSKAhERGJOQSAiEnMKAhGRmFMQiIjEnIJAZAqZ2blmdlfUdYiMpiAQEYk5BYHIOMzs8nA++E1m9p1wArBOM/vPcH74e82sItx2lZk9Fk5sdufwxGZmttjM7gnnlH/KzE4I3z7fzG43s21m9uPwqliRyCgIRMYws5OAy4Azw0m/BoG/BPKAWnc/GXiQ4ApjgFuAq919BcGVrcPLfwx8291XAmcQTHoGwcyYnwZeAywCzkz6QYkcQ8af3kQkdi4ATgWeDP9YzyGYgG0IuC3c5kfAHWZWBBS7+4Ph8puBn4dzRs1x9zsB3L0XIHy/J9x9b/j7JmABwY1HRCKhIBB5OQNudvcvHLHQ7P+O2e7Vzs8yem6YQfT/oURMTUMiL3cvcImZVcLIvXznE/z/Mjzz4/uBR9y9DThkZmeHyz8APBjeJWuvmb0rfI9sM8ud0qMQmSD9JSIyhrs/Z2ZfJLhTXBpwGPgE0AWsCdc1EfQjQDAd8A3hF/1O4EPh8g8A3zGza8L3eM8UHobIhGn2UZEJMrNOd8+Pug6RyaamIRGRmNMZgYhIzOmMQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYu7/A+3/fpTOyf0SAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}